# ðŸ§  AWS Sentiment Analysis Pipeline

This repository implements an end-to-end sentiment analysis pipeline using AWS services with fully automated CI/CD using GitHub Actions. It handles data ingestion, preprocessing, model training, evaluation, and deployment with a web-based user interface.

---

## ðŸ“ Project Structure

```
sentiment-app/
â”œâ”€â”€ backend/                # FastAPI backend APIs
â”‚   â”œâ”€â”€ main.py             # Entry point for FastAPI
â”‚   â”œâ”€â”€ routes/             # API endpoints
â”‚   â””â”€â”€ utils/              # Utility functions
â”œâ”€â”€ frontend/               # Streamlit user interface
â”‚   â””â”€â”€ streamlit_app.py    # Frontend application
â”œâ”€â”€ sentiment-pipeline/     # PySpark + BERT inference logic
â”‚   â”œâ”€â”€ run_clean.py        # Preprocessing
â”‚   â”œâ”€â”€ run_infer.py        # Inference
â”‚   â””â”€â”€ run_all.py          # Combined pipeline for ECS
â”œâ”€â”€ Dockerfile              # Containerization for Spark + Transformers
â”œâ”€â”€ requirements.txt        # Unified Python dependencies
â””â”€â”€ .github/workflows/      # GitHub Actions CI/CD workflows
```

---

## ðŸ”„ Data Pipeline (AWS Glue)

| Step              | Script                  | Input                             | Output                                  |
| ----------------- | ----------------------- | --------------------------------- | --------------------------------------- |
| Preprocessing     | `data_preprocessing.py` | `Bronze/train.parquet`            | `Bronze/pre_processed.parquet`          |
| Schema Validation | `schema_validation.py`  | `Bronze/pre_processed.parquet`    | `Bronze/schema_validated.parquet`       |
| Anomaly Detection | `anomaly_detection.py`  | `Bronze/schema_validated.parquet` | `Bronze/anomaly_flagged.parquet`        |
| Sampling          | `sampling.py`           | `Bronze/anomaly_flagged.parquet`  | `Silver/sampled.csv`, `Silver/test.csv` |

**Orchestrated via**: AWS Glue Workflows

---

## ðŸ¤— Model Training & Evaluation (SageMaker)

* **Model**: DistilBERT
* **Training**: AWS SageMaker (`Silver/sampled.csv`)
* **Evaluation**: Local using Hugging Face `Trainer.evaluate()` on `Silver/test.csv`
* **Metrics**:

  * Accuracy: 93.14%
  * Precision: 94.34%
  * Recall: 91.78%
  * F1 Score: 93.05%
* **Artifacts**: `s3://mlops-sentiment-analysis-data/models/model.tar.gz`

---

## ðŸš€ Deployment

### ðŸ–¥ï¸ Backend (FastAPI)

* `/login` - AWS Cognito
* `/trigger_pipeline` - Launch ECS job
* `/generate_dashboard` - Generate dashboard

### ðŸŒ Frontend (Streamlit)

* Upload CSV â†’ Trigger pipeline â†’ View dashboard
* Polls ECS job status in real-time

### ðŸ³ ECS Fargate Execution

* `run_all.py`: Executes preprocessing and inference using Spark and Transformers
* Output saved to S3: `processed/{user}/processed.csv`, `output/{user}/served.csv`

---

## ðŸ” CI/CD (GitHub Actions)

### âœ… Continuous Integration (CI)

* Run on every push
* Installs dependencies
* Executes unit tests with `pytest`

### ðŸš€ Continuous Deployment (CD)

* Builds Docker image
* Pushes to AWS ECR
* Deploys updated image to ECS task
* Triggers SageMaker training and logs output to MLflow

---

## ðŸ” Environment Setup

* `.env` file includes credentials for Cognito, ECS, and S3
* Transferred securely via SCP to EC2 instance

---

## ðŸ“Š Visual Overview

### ðŸ”¸ Data + Model + Deployment Pipeline

```mermaid
flowchart TD
    A[Upload CSV via Streamlit] --> B[FastAPI Trigger]
    B --> C[ECS Fargate: run_all.py]
    C --> D[S3: processed.csv + served.csv]
    D --> E[FastAPI: generate_dashboard]
    E --> F[Streamlit: Display Results]
```

---

## ðŸ“ S3 Bucket Structure

```
s3://mlops-sentiment-analysis-data/
â”œâ”€â”€ raw/
â”œâ”€â”€ Bronze/
â”œâ”€â”€ Silver/
â”œâ”€â”€ test/
â”œâ”€â”€ output/{user}/served.csv
â”œâ”€â”€ processed/{user}/processed.csv
â”œâ”€â”€ metadata/
```

---

## ðŸ“¡ Monitoring & Logs

```bash
# Backend logs
$ tail -f fastapi.log

# Frontend logs
$ tail -f streamlit.log
```

---

## ðŸ™Œ Credits

Built using: AWS Glue, SageMaker, ECS Fargate, EC2, FastAPI, Streamlit, HuggingFace, PySpark, MLflow

---

## Teammates
Aniruthan S A & Janani Karthikeyan

> âœ¨ Fully CI/CD-enabled, cloud-optimized sentiment analysis app ready for production!
